model:
  - MorganFP
device:
  - cuda
batch_size:
  - 32
  - 64
learning_rate:
  - 0.01
l2:
  - 0.
num_epochs:
  - 50
num_lrs:
    - 1
optimizer:
  - Adam
scheduler:
  -
    class: NoamLR
    args:
      warmup_epochs: [2.0]
      step_size: 10
      max_lr: [0.0001]
      init_lr: [0.00001]
      final_lr: [0.00001]
gradient_clipping:
  - null
early_stopper:
  -
    class: Patience
    args:
      patience: 500
      use_loss: True
shuffle:
  - True
hidden_units:
  - 128